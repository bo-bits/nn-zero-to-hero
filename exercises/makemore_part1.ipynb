{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlKl2cuA7GrGXzKVxduHvj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bo-bits/nn-zero-to-hero/blob/master/exercises/makemore_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
      ],
      "metadata": {
        "id": "s6FNrkKZEiLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigram Model\n",
        "\n",
        "words = open('names.txt', 'r').read().splitlines()\n"
      ],
      "metadata": {
        "id": "3hCniXWZE5dA"
      },
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dictionaries stoi itos\n",
        "\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "\n",
        "chars.insert(0, '.')  # Insert the period as the first character\n",
        "\n",
        "# Initialize stoi for single characters\n",
        "stoi = {char: i for i, char in enumerate(chars)}  # Single character to index mapping\n",
        "\n",
        "# Start bigram indices after the single characters\n",
        "bigram_start_idx = len(stoi)\n",
        "\n",
        "# Add bigrams to stoi with unique indices\n",
        "for i, (char1, char2) in enumerate((a + b for a in chars for b in chars), bigram_start_idx):\n",
        "    stoi[char1 + char2] = i\n",
        "\n",
        "# Create itos for reverse mapping\n",
        "\n",
        "stoi"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n5wW-UlMvvtL",
        "outputId": "8149d3b7-83b7-4b45-e18b-e6baaa76924b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 0,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26,\n",
              " '..': 27,\n",
              " '.a': 28,\n",
              " '.b': 29,\n",
              " '.c': 30,\n",
              " '.d': 31,\n",
              " '.e': 32,\n",
              " '.f': 33,\n",
              " '.g': 34,\n",
              " '.h': 35,\n",
              " '.i': 36,\n",
              " '.j': 37,\n",
              " '.k': 38,\n",
              " '.l': 39,\n",
              " '.m': 40,\n",
              " '.n': 41,\n",
              " '.o': 42,\n",
              " '.p': 43,\n",
              " '.q': 44,\n",
              " '.r': 45,\n",
              " '.s': 46,\n",
              " '.t': 47,\n",
              " '.u': 48,\n",
              " '.v': 49,\n",
              " '.w': 50,\n",
              " '.x': 51,\n",
              " '.y': 52,\n",
              " '.z': 53,\n",
              " 'a.': 54,\n",
              " 'aa': 55,\n",
              " 'ab': 56,\n",
              " 'ac': 57,\n",
              " 'ad': 58,\n",
              " 'ae': 59,\n",
              " 'af': 60,\n",
              " 'ag': 61,\n",
              " 'ah': 62,\n",
              " 'ai': 63,\n",
              " 'aj': 64,\n",
              " 'ak': 65,\n",
              " 'al': 66,\n",
              " 'am': 67,\n",
              " 'an': 68,\n",
              " 'ao': 69,\n",
              " 'ap': 70,\n",
              " 'aq': 71,\n",
              " 'ar': 72,\n",
              " 'as': 73,\n",
              " 'at': 74,\n",
              " 'au': 75,\n",
              " 'av': 76,\n",
              " 'aw': 77,\n",
              " 'ax': 78,\n",
              " 'ay': 79,\n",
              " 'az': 80,\n",
              " 'b.': 81,\n",
              " 'ba': 82,\n",
              " 'bb': 83,\n",
              " 'bc': 84,\n",
              " 'bd': 85,\n",
              " 'be': 86,\n",
              " 'bf': 87,\n",
              " 'bg': 88,\n",
              " 'bh': 89,\n",
              " 'bi': 90,\n",
              " 'bj': 91,\n",
              " 'bk': 92,\n",
              " 'bl': 93,\n",
              " 'bm': 94,\n",
              " 'bn': 95,\n",
              " 'bo': 96,\n",
              " 'bp': 97,\n",
              " 'bq': 98,\n",
              " 'br': 99,\n",
              " 'bs': 100,\n",
              " 'bt': 101,\n",
              " 'bu': 102,\n",
              " 'bv': 103,\n",
              " 'bw': 104,\n",
              " 'bx': 105,\n",
              " 'by': 106,\n",
              " 'bz': 107,\n",
              " 'c.': 108,\n",
              " 'ca': 109,\n",
              " 'cb': 110,\n",
              " 'cc': 111,\n",
              " 'cd': 112,\n",
              " 'ce': 113,\n",
              " 'cf': 114,\n",
              " 'cg': 115,\n",
              " 'ch': 116,\n",
              " 'ci': 117,\n",
              " 'cj': 118,\n",
              " 'ck': 119,\n",
              " 'cl': 120,\n",
              " 'cm': 121,\n",
              " 'cn': 122,\n",
              " 'co': 123,\n",
              " 'cp': 124,\n",
              " 'cq': 125,\n",
              " 'cr': 126,\n",
              " 'cs': 127,\n",
              " 'ct': 128,\n",
              " 'cu': 129,\n",
              " 'cv': 130,\n",
              " 'cw': 131,\n",
              " 'cx': 132,\n",
              " 'cy': 133,\n",
              " 'cz': 134,\n",
              " 'd.': 135,\n",
              " 'da': 136,\n",
              " 'db': 137,\n",
              " 'dc': 138,\n",
              " 'dd': 139,\n",
              " 'de': 140,\n",
              " 'df': 141,\n",
              " 'dg': 142,\n",
              " 'dh': 143,\n",
              " 'di': 144,\n",
              " 'dj': 145,\n",
              " 'dk': 146,\n",
              " 'dl': 147,\n",
              " 'dm': 148,\n",
              " 'dn': 149,\n",
              " 'do': 150,\n",
              " 'dp': 151,\n",
              " 'dq': 152,\n",
              " 'dr': 153,\n",
              " 'ds': 154,\n",
              " 'dt': 155,\n",
              " 'du': 156,\n",
              " 'dv': 157,\n",
              " 'dw': 158,\n",
              " 'dx': 159,\n",
              " 'dy': 160,\n",
              " 'dz': 161,\n",
              " 'e.': 162,\n",
              " 'ea': 163,\n",
              " 'eb': 164,\n",
              " 'ec': 165,\n",
              " 'ed': 166,\n",
              " 'ee': 167,\n",
              " 'ef': 168,\n",
              " 'eg': 169,\n",
              " 'eh': 170,\n",
              " 'ei': 171,\n",
              " 'ej': 172,\n",
              " 'ek': 173,\n",
              " 'el': 174,\n",
              " 'em': 175,\n",
              " 'en': 176,\n",
              " 'eo': 177,\n",
              " 'ep': 178,\n",
              " 'eq': 179,\n",
              " 'er': 180,\n",
              " 'es': 181,\n",
              " 'et': 182,\n",
              " 'eu': 183,\n",
              " 'ev': 184,\n",
              " 'ew': 185,\n",
              " 'ex': 186,\n",
              " 'ey': 187,\n",
              " 'ez': 188,\n",
              " 'f.': 189,\n",
              " 'fa': 190,\n",
              " 'fb': 191,\n",
              " 'fc': 192,\n",
              " 'fd': 193,\n",
              " 'fe': 194,\n",
              " 'ff': 195,\n",
              " 'fg': 196,\n",
              " 'fh': 197,\n",
              " 'fi': 198,\n",
              " 'fj': 199,\n",
              " 'fk': 200,\n",
              " 'fl': 201,\n",
              " 'fm': 202,\n",
              " 'fn': 203,\n",
              " 'fo': 204,\n",
              " 'fp': 205,\n",
              " 'fq': 206,\n",
              " 'fr': 207,\n",
              " 'fs': 208,\n",
              " 'ft': 209,\n",
              " 'fu': 210,\n",
              " 'fv': 211,\n",
              " 'fw': 212,\n",
              " 'fx': 213,\n",
              " 'fy': 214,\n",
              " 'fz': 215,\n",
              " 'g.': 216,\n",
              " 'ga': 217,\n",
              " 'gb': 218,\n",
              " 'gc': 219,\n",
              " 'gd': 220,\n",
              " 'ge': 221,\n",
              " 'gf': 222,\n",
              " 'gg': 223,\n",
              " 'gh': 224,\n",
              " 'gi': 225,\n",
              " 'gj': 226,\n",
              " 'gk': 227,\n",
              " 'gl': 228,\n",
              " 'gm': 229,\n",
              " 'gn': 230,\n",
              " 'go': 231,\n",
              " 'gp': 232,\n",
              " 'gq': 233,\n",
              " 'gr': 234,\n",
              " 'gs': 235,\n",
              " 'gt': 236,\n",
              " 'gu': 237,\n",
              " 'gv': 238,\n",
              " 'gw': 239,\n",
              " 'gx': 240,\n",
              " 'gy': 241,\n",
              " 'gz': 242,\n",
              " 'h.': 243,\n",
              " 'ha': 244,\n",
              " 'hb': 245,\n",
              " 'hc': 246,\n",
              " 'hd': 247,\n",
              " 'he': 248,\n",
              " 'hf': 249,\n",
              " 'hg': 250,\n",
              " 'hh': 251,\n",
              " 'hi': 252,\n",
              " 'hj': 253,\n",
              " 'hk': 254,\n",
              " 'hl': 255,\n",
              " 'hm': 256,\n",
              " 'hn': 257,\n",
              " 'ho': 258,\n",
              " 'hp': 259,\n",
              " 'hq': 260,\n",
              " 'hr': 261,\n",
              " 'hs': 262,\n",
              " 'ht': 263,\n",
              " 'hu': 264,\n",
              " 'hv': 265,\n",
              " 'hw': 266,\n",
              " 'hx': 267,\n",
              " 'hy': 268,\n",
              " 'hz': 269,\n",
              " 'i.': 270,\n",
              " 'ia': 271,\n",
              " 'ib': 272,\n",
              " 'ic': 273,\n",
              " 'id': 274,\n",
              " 'ie': 275,\n",
              " 'if': 276,\n",
              " 'ig': 277,\n",
              " 'ih': 278,\n",
              " 'ii': 279,\n",
              " 'ij': 280,\n",
              " 'ik': 281,\n",
              " 'il': 282,\n",
              " 'im': 283,\n",
              " 'in': 284,\n",
              " 'io': 285,\n",
              " 'ip': 286,\n",
              " 'iq': 287,\n",
              " 'ir': 288,\n",
              " 'is': 289,\n",
              " 'it': 290,\n",
              " 'iu': 291,\n",
              " 'iv': 292,\n",
              " 'iw': 293,\n",
              " 'ix': 294,\n",
              " 'iy': 295,\n",
              " 'iz': 296,\n",
              " 'j.': 297,\n",
              " 'ja': 298,\n",
              " 'jb': 299,\n",
              " 'jc': 300,\n",
              " 'jd': 301,\n",
              " 'je': 302,\n",
              " 'jf': 303,\n",
              " 'jg': 304,\n",
              " 'jh': 305,\n",
              " 'ji': 306,\n",
              " 'jj': 307,\n",
              " 'jk': 308,\n",
              " 'jl': 309,\n",
              " 'jm': 310,\n",
              " 'jn': 311,\n",
              " 'jo': 312,\n",
              " 'jp': 313,\n",
              " 'jq': 314,\n",
              " 'jr': 315,\n",
              " 'js': 316,\n",
              " 'jt': 317,\n",
              " 'ju': 318,\n",
              " 'jv': 319,\n",
              " 'jw': 320,\n",
              " 'jx': 321,\n",
              " 'jy': 322,\n",
              " 'jz': 323,\n",
              " 'k.': 324,\n",
              " 'ka': 325,\n",
              " 'kb': 326,\n",
              " 'kc': 327,\n",
              " 'kd': 328,\n",
              " 'ke': 329,\n",
              " 'kf': 330,\n",
              " 'kg': 331,\n",
              " 'kh': 332,\n",
              " 'ki': 333,\n",
              " 'kj': 334,\n",
              " 'kk': 335,\n",
              " 'kl': 336,\n",
              " 'km': 337,\n",
              " 'kn': 338,\n",
              " 'ko': 339,\n",
              " 'kp': 340,\n",
              " 'kq': 341,\n",
              " 'kr': 342,\n",
              " 'ks': 343,\n",
              " 'kt': 344,\n",
              " 'ku': 345,\n",
              " 'kv': 346,\n",
              " 'kw': 347,\n",
              " 'kx': 348,\n",
              " 'ky': 349,\n",
              " 'kz': 350,\n",
              " 'l.': 351,\n",
              " 'la': 352,\n",
              " 'lb': 353,\n",
              " 'lc': 354,\n",
              " 'ld': 355,\n",
              " 'le': 356,\n",
              " 'lf': 357,\n",
              " 'lg': 358,\n",
              " 'lh': 359,\n",
              " 'li': 360,\n",
              " 'lj': 361,\n",
              " 'lk': 362,\n",
              " 'll': 363,\n",
              " 'lm': 364,\n",
              " 'ln': 365,\n",
              " 'lo': 366,\n",
              " 'lp': 367,\n",
              " 'lq': 368,\n",
              " 'lr': 369,\n",
              " 'ls': 370,\n",
              " 'lt': 371,\n",
              " 'lu': 372,\n",
              " 'lv': 373,\n",
              " 'lw': 374,\n",
              " 'lx': 375,\n",
              " 'ly': 376,\n",
              " 'lz': 377,\n",
              " 'm.': 378,\n",
              " 'ma': 379,\n",
              " 'mb': 380,\n",
              " 'mc': 381,\n",
              " 'md': 382,\n",
              " 'me': 383,\n",
              " 'mf': 384,\n",
              " 'mg': 385,\n",
              " 'mh': 386,\n",
              " 'mi': 387,\n",
              " 'mj': 388,\n",
              " 'mk': 389,\n",
              " 'ml': 390,\n",
              " 'mm': 391,\n",
              " 'mn': 392,\n",
              " 'mo': 393,\n",
              " 'mp': 394,\n",
              " 'mq': 395,\n",
              " 'mr': 396,\n",
              " 'ms': 397,\n",
              " 'mt': 398,\n",
              " 'mu': 399,\n",
              " 'mv': 400,\n",
              " 'mw': 401,\n",
              " 'mx': 402,\n",
              " 'my': 403,\n",
              " 'mz': 404,\n",
              " 'n.': 405,\n",
              " 'na': 406,\n",
              " 'nb': 407,\n",
              " 'nc': 408,\n",
              " 'nd': 409,\n",
              " 'ne': 410,\n",
              " 'nf': 411,\n",
              " 'ng': 412,\n",
              " 'nh': 413,\n",
              " 'ni': 414,\n",
              " 'nj': 415,\n",
              " 'nk': 416,\n",
              " 'nl': 417,\n",
              " 'nm': 418,\n",
              " 'nn': 419,\n",
              " 'no': 420,\n",
              " 'np': 421,\n",
              " 'nq': 422,\n",
              " 'nr': 423,\n",
              " 'ns': 424,\n",
              " 'nt': 425,\n",
              " 'nu': 426,\n",
              " 'nv': 427,\n",
              " 'nw': 428,\n",
              " 'nx': 429,\n",
              " 'ny': 430,\n",
              " 'nz': 431,\n",
              " 'o.': 432,\n",
              " 'oa': 433,\n",
              " 'ob': 434,\n",
              " 'oc': 435,\n",
              " 'od': 436,\n",
              " 'oe': 437,\n",
              " 'of': 438,\n",
              " 'og': 439,\n",
              " 'oh': 440,\n",
              " 'oi': 441,\n",
              " 'oj': 442,\n",
              " 'ok': 443,\n",
              " 'ol': 444,\n",
              " 'om': 445,\n",
              " 'on': 446,\n",
              " 'oo': 447,\n",
              " 'op': 448,\n",
              " 'oq': 449,\n",
              " 'or': 450,\n",
              " 'os': 451,\n",
              " 'ot': 452,\n",
              " 'ou': 453,\n",
              " 'ov': 454,\n",
              " 'ow': 455,\n",
              " 'ox': 456,\n",
              " 'oy': 457,\n",
              " 'oz': 458,\n",
              " 'p.': 459,\n",
              " 'pa': 460,\n",
              " 'pb': 461,\n",
              " 'pc': 462,\n",
              " 'pd': 463,\n",
              " 'pe': 464,\n",
              " 'pf': 465,\n",
              " 'pg': 466,\n",
              " 'ph': 467,\n",
              " 'pi': 468,\n",
              " 'pj': 469,\n",
              " 'pk': 470,\n",
              " 'pl': 471,\n",
              " 'pm': 472,\n",
              " 'pn': 473,\n",
              " 'po': 474,\n",
              " 'pp': 475,\n",
              " 'pq': 476,\n",
              " 'pr': 477,\n",
              " 'ps': 478,\n",
              " 'pt': 479,\n",
              " 'pu': 480,\n",
              " 'pv': 481,\n",
              " 'pw': 482,\n",
              " 'px': 483,\n",
              " 'py': 484,\n",
              " 'pz': 485,\n",
              " 'q.': 486,\n",
              " 'qa': 487,\n",
              " 'qb': 488,\n",
              " 'qc': 489,\n",
              " 'qd': 490,\n",
              " 'qe': 491,\n",
              " 'qf': 492,\n",
              " 'qg': 493,\n",
              " 'qh': 494,\n",
              " 'qi': 495,\n",
              " 'qj': 496,\n",
              " 'qk': 497,\n",
              " 'ql': 498,\n",
              " 'qm': 499,\n",
              " 'qn': 500,\n",
              " 'qo': 501,\n",
              " 'qp': 502,\n",
              " 'qq': 503,\n",
              " 'qr': 504,\n",
              " 'qs': 505,\n",
              " 'qt': 506,\n",
              " 'qu': 507,\n",
              " 'qv': 508,\n",
              " 'qw': 509,\n",
              " 'qx': 510,\n",
              " 'qy': 511,\n",
              " 'qz': 512,\n",
              " 'r.': 513,\n",
              " 'ra': 514,\n",
              " 'rb': 515,\n",
              " 'rc': 516,\n",
              " 'rd': 517,\n",
              " 're': 518,\n",
              " 'rf': 519,\n",
              " 'rg': 520,\n",
              " 'rh': 521,\n",
              " 'ri': 522,\n",
              " 'rj': 523,\n",
              " 'rk': 524,\n",
              " 'rl': 525,\n",
              " 'rm': 526,\n",
              " 'rn': 527,\n",
              " 'ro': 528,\n",
              " 'rp': 529,\n",
              " 'rq': 530,\n",
              " 'rr': 531,\n",
              " 'rs': 532,\n",
              " 'rt': 533,\n",
              " 'ru': 534,\n",
              " 'rv': 535,\n",
              " 'rw': 536,\n",
              " 'rx': 537,\n",
              " 'ry': 538,\n",
              " 'rz': 539,\n",
              " 's.': 540,\n",
              " 'sa': 541,\n",
              " 'sb': 542,\n",
              " 'sc': 543,\n",
              " 'sd': 544,\n",
              " 'se': 545,\n",
              " 'sf': 546,\n",
              " 'sg': 547,\n",
              " 'sh': 548,\n",
              " 'si': 549,\n",
              " 'sj': 550,\n",
              " 'sk': 551,\n",
              " 'sl': 552,\n",
              " 'sm': 553,\n",
              " 'sn': 554,\n",
              " 'so': 555,\n",
              " 'sp': 556,\n",
              " 'sq': 557,\n",
              " 'sr': 558,\n",
              " 'ss': 559,\n",
              " 'st': 560,\n",
              " 'su': 561,\n",
              " 'sv': 562,\n",
              " 'sw': 563,\n",
              " 'sx': 564,\n",
              " 'sy': 565,\n",
              " 'sz': 566,\n",
              " 't.': 567,\n",
              " 'ta': 568,\n",
              " 'tb': 569,\n",
              " 'tc': 570,\n",
              " 'td': 571,\n",
              " 'te': 572,\n",
              " 'tf': 573,\n",
              " 'tg': 574,\n",
              " 'th': 575,\n",
              " 'ti': 576,\n",
              " 'tj': 577,\n",
              " 'tk': 578,\n",
              " 'tl': 579,\n",
              " 'tm': 580,\n",
              " 'tn': 581,\n",
              " 'to': 582,\n",
              " 'tp': 583,\n",
              " 'tq': 584,\n",
              " 'tr': 585,\n",
              " 'ts': 586,\n",
              " 'tt': 587,\n",
              " 'tu': 588,\n",
              " 'tv': 589,\n",
              " 'tw': 590,\n",
              " 'tx': 591,\n",
              " 'ty': 592,\n",
              " 'tz': 593,\n",
              " 'u.': 594,\n",
              " 'ua': 595,\n",
              " 'ub': 596,\n",
              " 'uc': 597,\n",
              " 'ud': 598,\n",
              " 'ue': 599,\n",
              " 'uf': 600,\n",
              " 'ug': 601,\n",
              " 'uh': 602,\n",
              " 'ui': 603,\n",
              " 'uj': 604,\n",
              " 'uk': 605,\n",
              " 'ul': 606,\n",
              " 'um': 607,\n",
              " 'un': 608,\n",
              " 'uo': 609,\n",
              " 'up': 610,\n",
              " 'uq': 611,\n",
              " 'ur': 612,\n",
              " 'us': 613,\n",
              " 'ut': 614,\n",
              " 'uu': 615,\n",
              " 'uv': 616,\n",
              " 'uw': 617,\n",
              " 'ux': 618,\n",
              " 'uy': 619,\n",
              " 'uz': 620,\n",
              " 'v.': 621,\n",
              " 'va': 622,\n",
              " 'vb': 623,\n",
              " 'vc': 624,\n",
              " 'vd': 625,\n",
              " 've': 626,\n",
              " 'vf': 627,\n",
              " 'vg': 628,\n",
              " 'vh': 629,\n",
              " 'vi': 630,\n",
              " 'vj': 631,\n",
              " 'vk': 632,\n",
              " 'vl': 633,\n",
              " 'vm': 634,\n",
              " 'vn': 635,\n",
              " 'vo': 636,\n",
              " 'vp': 637,\n",
              " 'vq': 638,\n",
              " 'vr': 639,\n",
              " 'vs': 640,\n",
              " 'vt': 641,\n",
              " 'vu': 642,\n",
              " 'vv': 643,\n",
              " 'vw': 644,\n",
              " 'vx': 645,\n",
              " 'vy': 646,\n",
              " 'vz': 647,\n",
              " 'w.': 648,\n",
              " 'wa': 649,\n",
              " 'wb': 650,\n",
              " 'wc': 651,\n",
              " 'wd': 652,\n",
              " 'we': 653,\n",
              " 'wf': 654,\n",
              " 'wg': 655,\n",
              " 'wh': 656,\n",
              " 'wi': 657,\n",
              " 'wj': 658,\n",
              " 'wk': 659,\n",
              " 'wl': 660,\n",
              " 'wm': 661,\n",
              " 'wn': 662,\n",
              " 'wo': 663,\n",
              " 'wp': 664,\n",
              " 'wq': 665,\n",
              " 'wr': 666,\n",
              " 'ws': 667,\n",
              " 'wt': 668,\n",
              " 'wu': 669,\n",
              " 'wv': 670,\n",
              " 'ww': 671,\n",
              " 'wx': 672,\n",
              " 'wy': 673,\n",
              " 'wz': 674,\n",
              " 'x.': 675,\n",
              " 'xa': 676,\n",
              " 'xb': 677,\n",
              " 'xc': 678,\n",
              " 'xd': 679,\n",
              " 'xe': 680,\n",
              " 'xf': 681,\n",
              " 'xg': 682,\n",
              " 'xh': 683,\n",
              " 'xi': 684,\n",
              " 'xj': 685,\n",
              " 'xk': 686,\n",
              " 'xl': 687,\n",
              " 'xm': 688,\n",
              " 'xn': 689,\n",
              " 'xo': 690,\n",
              " 'xp': 691,\n",
              " 'xq': 692,\n",
              " 'xr': 693,\n",
              " 'xs': 694,\n",
              " 'xt': 695,\n",
              " 'xu': 696,\n",
              " 'xv': 697,\n",
              " 'xw': 698,\n",
              " 'xx': 699,\n",
              " 'xy': 700,\n",
              " 'xz': 701,\n",
              " 'y.': 702,\n",
              " 'ya': 703,\n",
              " 'yb': 704,\n",
              " 'yc': 705,\n",
              " 'yd': 706,\n",
              " 'ye': 707,\n",
              " 'yf': 708,\n",
              " 'yg': 709,\n",
              " 'yh': 710,\n",
              " 'yi': 711,\n",
              " 'yj': 712,\n",
              " 'yk': 713,\n",
              " 'yl': 714,\n",
              " 'ym': 715,\n",
              " 'yn': 716,\n",
              " 'yo': 717,\n",
              " 'yp': 718,\n",
              " 'yq': 719,\n",
              " 'yr': 720,\n",
              " 'ys': 721,\n",
              " 'yt': 722,\n",
              " 'yu': 723,\n",
              " 'yv': 724,\n",
              " 'yw': 725,\n",
              " 'yx': 726,\n",
              " 'yy': 727,\n",
              " 'yz': 728,\n",
              " 'z.': 729,\n",
              " 'za': 730,\n",
              " 'zb': 731,\n",
              " 'zc': 732,\n",
              " 'zd': 733,\n",
              " 'ze': 734,\n",
              " 'zf': 735,\n",
              " 'zg': 736,\n",
              " 'zh': 737,\n",
              " 'zi': 738,\n",
              " 'zj': 739,\n",
              " 'zk': 740,\n",
              " 'zl': 741,\n",
              " 'zm': 742,\n",
              " 'zn': 743,\n",
              " 'zo': 744,\n",
              " 'zp': 745,\n",
              " 'zq': 746,\n",
              " 'zr': 747,\n",
              " 'zs': 748,\n",
              " 'zt': 749,\n",
              " 'zu': 750,\n",
              " 'zv': 751,\n",
              " 'zw': 752,\n",
              " 'zx': 753,\n",
              " 'zy': 754,\n",
              " 'zz': 755}"
            ]
          },
          "metadata": {},
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Initialize\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((756, 27), generator=g, requires_grad=True)\n",
        "\n",
        "# create the training set of trigrams (x,y)\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1+ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix3)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)"
      ],
      "metadata": {
        "id": "AOF8XEaVjo8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=756).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean()\n",
        "  print(f\"Loss: \",loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  # Calculated by pytoch by computing gradients\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "  W.data += -50 * W.grad"
      ],
      "metadata": {
        "collapsed": true,
        "id": "op4jJpqQrW6_",
        "outputId": "4614f6ef-1178-4bd9-c063-a1e6a07fb98c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  3.786095142364502\n",
            "Loss:  3.4637839794158936\n",
            "Loss:  3.1635053157806396\n",
            "Loss:  2.8889341354370117\n",
            "Loss:  2.6438236236572266\n",
            "Loss:  2.429399251937866\n",
            "Loss:  2.2430198192596436\n",
            "Loss:  2.080261468887329\n",
            "Loss:  1.9371535778045654\n",
            "Loss:  1.8106318712234497\n",
            "Loss:  1.6983482837677002\n",
            "Loss:  1.5984528064727783\n",
            "Loss:  1.509432315826416\n",
            "Loss:  1.4300153255462646\n",
            "Loss:  1.359114646911621\n",
            "Loss:  1.295795202255249\n",
            "Loss:  1.23924720287323\n",
            "Loss:  1.1887630224227905\n",
            "Loss:  1.1437134742736816\n",
            "Loss:  1.1035327911376953\n",
            "Loss:  1.0677061080932617\n",
            "Loss:  1.035763144493103\n",
            "Loss:  1.007274866104126\n",
            "Loss:  0.9818510413169861\n",
            "Loss:  0.9591383934020996\n",
            "Loss:  0.9388185143470764\n",
            "Loss:  0.9206076264381409\n",
            "Loss:  0.9042524695396423\n",
            "Loss:  0.889529824256897\n",
            "Loss:  0.8762427568435669\n",
            "Loss:  0.8642190098762512\n",
            "Loss:  0.853307843208313\n",
            "Loss:  0.8433783054351807\n",
            "Loss:  0.8343161344528198\n",
            "Loss:  0.8260222673416138\n",
            "Loss:  0.8184104561805725\n",
            "Loss:  0.8114060163497925\n",
            "Loss:  0.8049435019493103\n",
            "Loss:  0.7989661693572998\n",
            "Loss:  0.7934243679046631\n",
            "Loss:  0.7882745862007141\n",
            "Loss:  0.783478856086731\n",
            "Loss:  0.7790030837059021\n",
            "Loss:  0.7748181223869324\n",
            "Loss:  0.7708972096443176\n",
            "Loss:  0.7672173380851746\n",
            "Loss:  0.7637577056884766\n",
            "Loss:  0.7604997754096985\n",
            "Loss:  0.757426917552948\n",
            "Loss:  0.7545243501663208\n",
            "Loss:  0.7517787218093872\n",
            "Loss:  0.7491780519485474\n",
            "Loss:  0.746711254119873\n",
            "Loss:  0.7443687319755554\n",
            "Loss:  0.7421413660049438\n",
            "Loss:  0.740021288394928\n",
            "Loss:  0.7380008101463318\n",
            "Loss:  0.73607337474823\n",
            "Loss:  0.7342328429222107\n",
            "Loss:  0.7324734926223755\n",
            "Loss:  0.7307901382446289\n",
            "Loss:  0.7291781306266785\n",
            "Loss:  0.7276329398155212\n",
            "Loss:  0.726150631904602\n",
            "Loss:  0.7247275710105896\n",
            "Loss:  0.7233601212501526\n",
            "Loss:  0.7220452427864075\n",
            "Loss:  0.7207798957824707\n",
            "Loss:  0.7195614576339722\n",
            "Loss:  0.7183871865272522\n",
            "Loss:  0.7172549962997437\n",
            "Loss:  0.7161624431610107\n",
            "Loss:  0.7151075005531311\n",
            "Loss:  0.7140883207321167\n",
            "Loss:  0.713103175163269\n",
            "Loss:  0.7121502757072449\n",
            "Loss:  0.7112280130386353\n",
            "Loss:  0.7103350162506104\n",
            "Loss:  0.7094697952270508\n",
            "Loss:  0.708631157875061\n",
            "Loss:  0.707817792892456\n",
            "Loss:  0.7070287466049194\n",
            "Loss:  0.7062626481056213\n",
            "Loss:  0.7055187225341797\n",
            "Loss:  0.7047958970069885\n",
            "Loss:  0.7040931582450867\n",
            "Loss:  0.7034099698066711\n",
            "Loss:  0.7027451992034912\n",
            "Loss:  0.7020981311798096\n",
            "Loss:  0.7014683485031128\n",
            "Loss:  0.7008546590805054\n",
            "Loss:  0.7002567648887634\n",
            "Loss:  0.6996739506721497\n",
            "Loss:  0.6991057395935059\n",
            "Loss:  0.69855135679245\n",
            "Loss:  0.6980105042457581\n",
            "Loss:  0.6974825263023376\n",
            "Loss:  0.6969669461250305\n",
            "Loss:  0.6964633464813232\n",
            "Loss:  0.6959713101387024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=756).float()\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "\n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "id": "DbeRDg5FoN59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the average negative log likelihood for a single example\n",
        "# what probability the model assigned to the correct output, take the log (high prob -> 0)\n",
        "# take negative, to make output positive\n",
        "# negative log likelihood is an indicator of how well the NN performed, we want to minimize\n",
        "nlls = torch.zeros(4)\n",
        "for i in range(4):\n",
        "  # i-th bigram:\n",
        "  x = xs[i].item() # input character index\n",
        "  y = ys[i].item() # label character index\n",
        "  print('--------')\n",
        "  print(f'bigram example {i+1}: {itob[x]}{itos[y]} (indexes {x},{y})')\n",
        "  print('input to the neural net:', x)\n",
        "  print('output probabilities from the neural net:', probs[i])\n",
        "  print('label (actual next character):', y)\n",
        "  p = probs[i, y]\n",
        "  print('probability assigned by the net to the the correct character:', p.item())\n",
        "  logp = torch.log(p)\n",
        "  print('log likelihood:', logp.item())\n",
        "  nll = -logp\n",
        "  print('negative log likelihood:', nll.item())\n",
        "  nlls[i] = nll\n",
        "\n",
        "print('=========')\n",
        "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMoSLxVSi_CF",
        "outputId": "a22f7ccc-05dd-482d-b2ed-b1c63019a598"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------\n",
            "bigram example 1: .ma (indexes 15,1)\n",
            "input to the neural net: 15\n",
            "output probabilities from the neural net: tensor([6.9801e-05, 9.9624e-01, 3.5564e-05, 2.3088e-04, 1.9466e-04, 5.6965e-05,\n",
            "        2.6365e-04, 4.2325e-04, 9.7273e-05, 7.0569e-05, 2.0174e-05, 3.0514e-04,\n",
            "        2.3514e-04, 1.6287e-04, 1.1365e-04, 7.4941e-05, 1.5874e-04, 7.9995e-05,\n",
            "        1.2383e-04, 1.8382e-05, 1.6627e-04, 2.1135e-04, 8.3075e-05, 2.9599e-05,\n",
            "        6.8066e-05, 1.1100e-04, 3.5287e-04], grad_fn=<SelectBackward0>)\n",
            "label (actual next character): 1\n",
            "probability assigned by the net to the the correct character: 0.9962422847747803\n",
            "log likelihood: -0.003764793276786804\n",
            "negative log likelihood: 0.003764793276786804\n",
            "--------\n",
            "bigram example 2: mar (indexes 367,18)\n",
            "input to the neural net: 367\n",
            "output probabilities from the neural net: tensor([1.3363e-05, 9.7108e-05, 1.5531e-04, 9.7857e-05, 1.5648e-04, 1.6445e-04,\n",
            "        1.0697e-04, 3.3253e-04, 6.3384e-05, 1.1796e-04, 4.3205e-04, 5.4818e-05,\n",
            "        2.3334e-04, 2.7704e-04, 9.9222e-05, 1.1108e-04, 1.8448e-04, 3.2874e-05,\n",
            "        9.9621e-01, 1.7526e-04, 1.3080e-04, 1.0562e-04, 1.3117e-04, 1.0593e-04,\n",
            "        5.3445e-05, 1.4985e-04, 2.0287e-04], grad_fn=<SelectBackward0>)\n",
            "label (actual next character): 18\n",
            "probability assigned by the net to the the correct character: 0.996214747428894\n",
            "log likelihood: -0.003792434697970748\n",
            "negative log likelihood: 0.003792434697970748\n",
            "--------\n",
            "bigram example 3: ary (indexes 48,25)\n",
            "input to the neural net: 48\n",
            "output probabilities from the neural net: tensor([1.9012e-04, 2.6508e-05, 1.6367e-04, 1.3088e-04, 1.3727e-04, 7.7178e-05,\n",
            "        3.2424e-05, 1.1402e-04, 2.3242e-04, 1.5891e-04, 1.9472e-04, 3.8014e-05,\n",
            "        8.2955e-05, 2.1665e-04, 1.9365e-04, 1.5874e-04, 3.2277e-04, 1.5514e-04,\n",
            "        1.8676e-04, 3.5148e-04, 1.5434e-04, 4.6356e-05, 2.4509e-04, 1.1210e-04,\n",
            "        3.0468e-05, 9.9618e-01, 7.1439e-05], grad_fn=<SelectBackward0>)\n",
            "label (actual next character): 25\n",
            "probability assigned by the net to the the correct character: 0.9961759448051453\n",
            "log likelihood: -0.0038313856348395348\n",
            "negative log likelihood: 0.0038313856348395348\n",
            "--------\n",
            "bigram example 4: ry. (indexes 531,0)\n",
            "input to the neural net: 531\n",
            "output probabilities from the neural net: tensor([9.9621e-01, 2.1175e-04, 1.0291e-04, 3.2360e-04, 1.0578e-04, 8.3688e-05,\n",
            "        2.3233e-04, 1.1343e-04, 2.5896e-05, 3.6214e-05, 7.8787e-05, 1.1574e-04,\n",
            "        2.7606e-05, 2.6704e-04, 1.3530e-04, 1.2657e-04, 4.1064e-04, 2.1637e-04,\n",
            "        2.3147e-05, 6.8998e-05, 3.4374e-05, 4.2006e-05, 1.4040e-04, 3.6410e-04,\n",
            "        1.9426e-04, 1.5527e-04, 1.5295e-04], grad_fn=<SelectBackward0>)\n",
            "label (actual next character): 0\n",
            "probability assigned by the net to the the correct character: 0.9962107539176941\n",
            "log likelihood: -0.0037964435759931803\n",
            "negative log likelihood: 0.0037964435759931803\n",
            "=========\n",
            "average negative log likelihood, i.e. loss = 0.003796264296397567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E02: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
      ],
      "metadata": {
        "id": "1E_da2qIEtE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2"
      ],
      "metadata": {
        "id": "r8n7rr1gc9PZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E03: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?"
      ],
      "metadata": {
        "id": "Nm5lYMRQEwyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1"
      ],
      "metadata": {
        "id": "FuLMP9Atc_g7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E04: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?"
      ],
      "metadata": {
        "id": "OOzpQ4y7Ez99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "E05: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
      ],
      "metadata": {
        "id": "8VFHbjP8E1Zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "E06: meta-exercise! Think of a fun/interesting exercise and complete it."
      ],
      "metadata": {
        "id": "E3yrXzL7E2oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd75241zCTcw"
      },
      "outputs": [],
      "source": []
    }
  ]
}